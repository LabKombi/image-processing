{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"archive/train\"\n",
    "processed_folder = \"D:\\\\2. College project\\\\sem 5 drowsiness detection while driving\\\\driver_drowsiness_system_CNN\\\\new_test_processing_1\"\n",
    "predictor = dlib.shape_predictor('data/shape_predictor_68_face_landmarks.dat')\n",
    "face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sharpening(image):\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    return cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "def remove_noise_gaussian(image, kernel_size=(3, 3)):\n",
    "    return cv2.GaussianBlur(image, kernel_size, 0)\n",
    "\n",
    "def remove_noise_bilateral(image, diameter=9, sigma_color=75, sigma_space=75):\n",
    "    return cv2.bilateralFilter(image, diameter, sigma_color, sigma_space)\n",
    "\n",
    "def normalize_image(image):\n",
    "    return image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eye_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to read image: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    denoised_img = remove_noise_bilateral(img)\n",
    "\n",
    "    sharpened_img = apply_sharpening(denoised_img)\n",
    "\n",
    "    resized_img = cv2.resize(sharpened_img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    normalized_img = normalize_image(resized_img)\n",
    "\n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_yawn_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to read image: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    faces = detector(img, 1)\n",
    "    if len(faces) == 0:\n",
    "        print(f\"No face detected in image: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(img, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        mouth_points = landmarks[48:68]\n",
    "        (x_min, y_min) = mouth_points.min(axis=0)\n",
    "        (x_max, y_max) = mouth_points.max(axis=0)\n",
    "\n",
    "        margin = 15\n",
    "        x_min = max(0, x_min - margin)\n",
    "        y_min = max(0, y_min - margin)\n",
    "        x_max = min(img.shape[1], x_max + margin)\n",
    "        y_max = min(img.shape[0], y_max + margin)\n",
    "\n",
    "        cropped_img = img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        denoised_img = remove_noise_bilateral(cropped_img)\n",
    "\n",
    "        sharpened_img = apply_sharpening(denoised_img)\n",
    "\n",
    "        resized_img = cv2.resize(sharpened_img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        normalized_img = normalize_image(resized_img)\n",
    "\n",
    "        return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_processing_steps(original_img, steps, title_steps):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, len(steps) + 1, 1)\n",
    "    plt.imshow(original_img)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i, (step_img, title) in enumerate(zip(steps, title_steps)):\n",
    "        plt.subplot(1, len(steps) + 1, i + 2)\n",
    "        plt.imshow(step_img)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_with_plot(image_path, category):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to read image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    steps = [img_rgb]\n",
    "    titles = [\"Original\"]\n",
    "\n",
    "    if category in ['Closed', 'Open']:\n",
    "        denoised_img = remove_noise_bilateral(img_rgb)\n",
    "        sharpened_img = apply_sharpening(denoised_img)\n",
    "        resized_img = cv2.resize(sharpened_img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        normalized_img = normalize_image(resized_img)\n",
    "\n",
    "        steps.extend([denoised_img, sharpened_img, resized_img, normalized_img])\n",
    "        titles.extend([\"Denoised\", \"Sharpened\", \"Resized\", \"Normalized\"])\n",
    "\n",
    "    elif category in ['yawn', 'no_yawn']:\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        faces = detector(img_rgb, 1)\n",
    "        if len(faces) == 0:\n",
    "            print(f\"No face detected in image: {image_path}\")\n",
    "            return\n",
    "\n",
    "        for face in faces:\n",
    "            landmarks = predictor(img_rgb, face)\n",
    "            landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "            mouth_points = landmarks[48:68]\n",
    "            (x_min, y_min) = mouth_points.min(axis=0)\n",
    "            (x_max, y_max) = mouth_points.max(axis=0)\n",
    "\n",
    "            margin = 15\n",
    "            x_min = max(0, x_min - margin)\n",
    "            y_min = max(0, y_min - margin)\n",
    "            x_max = min(img_rgb.shape[1], x_max + margin)\n",
    "            y_max = min(img_rgb.shape[0], y_max + margin)\n",
    "\n",
    "            cropped_img = img_rgb[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            denoised_img = remove_noise_bilateral(cropped_img)\n",
    "            sharpened_img = apply_sharpening(denoised_img)\n",
    "            resized_img = cv2.resize(sharpened_img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "            normalized_img = normalize_image(resized_img)\n",
    "\n",
    "            steps.extend([cropped_img, denoised_img, sharpened_img, resized_img, normalized_img])\n",
    "            titles.extend([\"Mouth ROI\", \"Denoised\", \"Sharpened\", \"Resized\", \"Normalized\"])\n",
    "            break  \n",
    "\n",
    "    plot_processing_steps(img_rgb, steps, titles)\n",
    "\n",
    "def visualize_selected_images(categories):\n",
    "    for category, image_path in categories.items():\n",
    "        print(f\"Visualizing processing for category: {category}\")\n",
    "        preprocess_with_plot(image_path, category)\n",
    "\n",
    "categories = {\n",
    "    'Closed': \"archive/train/Closed/_0.jpg\",\n",
    "    'Open': \"archive/train/Open/_10.jpg\",\n",
    "    'yawn': \"archive/train/yawn/7.jpg\",\n",
    "    'no_yawn': \"archive/train/no_yawn/3.jpg\"\n",
    "}\n",
    "\n",
    "visualize_selected_images(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_images(input_folder, processed_folder):\n",
    "    if not os.path.exists(processed_folder):\n",
    "        os.makedirs(processed_folder)\n",
    "\n",
    "    for category in os.listdir(input_folder):\n",
    "        category_path = os.path.join(input_folder, category)\n",
    "        output_category_folder = os.path.join(processed_folder, category)\n",
    "        if not os.path.exists(output_category_folder):\n",
    "            os.makedirs(output_category_folder)\n",
    "\n",
    "        for filename in os.listdir(category_path):\n",
    "            image_path = os.path.join(category_path, filename)\n",
    "\n",
    "            if category in ['yawn', 'no_yawn']:\n",
    "                processed_image = preprocess_yawn_image(image_path)\n",
    "            elif category in ['Closed', 'Open']:\n",
    "                processed_image = preprocess_eye_image(image_path)\n",
    "            else:\n",
    "                print(f\"Skipped unknown category: {category}\")\n",
    "                continue\n",
    "\n",
    "            if processed_image is not None:\n",
    "                processed_image = (processed_image * 255).astype(np.uint8)\n",
    "                output_path = os.path.join(output_category_folder, filename)\n",
    "                cv2.imwrite(output_path, cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR))\n",
    "                print(f\"Processed and saved: {output_path}\")\n",
    "\n",
    "process_and_save_images(input_folder, processed_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
